{"cells":[{"cell_type":"markdown","source":[" ## Multiple Predictors - multiple linear regression\n"," Similar to the examples with regression trees, linear regression can add multiple predictor attributes. When adding multiple attributes, these can be all continuous, all categorical, or a mix of continuous and categorical predictors. When more than one attribute is added as preditors, the model is commonly referred to as multiple linear regression."],"metadata":{}},{"source":[".libPaths('../RPackages')\n","\n","library(tidyverse)\n","library(ggformula)\n","library(mosaic)\n","library(broom)\n","\n","theme_set(theme_bw())\n","\n","baby <- read_csv(\"https://raw.githubusercontent.com/lebebr01/statthink/master/data-raw/baby.csv\") %>%\n","  filter(gestational_days > 200)\n","head(baby)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" In this example, I want to go back to the baby data used earlier in the course. Previously, baby weight in ounces was used as the outcome and in separate analyses we considered gestational days and maternal smoker status attributes to predict the baby weight outcome. Below are some examples of the analysis with bootstrapped estimated effect distributions.\n","\n"," ### Continuous Predictor"],"metadata":{}},{"source":["baby_reg <- lm(birth_weight ~ gestational_days, data = baby)\n","resample_baby <- function(...) {\n","  baby_resample <- baby %>%\n","    sample_n(nrow(baby), replace = TRUE)\n","\n","  baby_resample %>%\n","    lm(birth_weight ~ gestational_days, data = .) %>%\n","    coef(.) %>%\n","    .[2] %>%\n","    data.frame()\n","}\n","baby_coef <- map(1:10000, resample_baby) %>%\n","  bind_rows()\n","names(baby_coef) <- 'slope'\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["gf_density(~ slope, data = baby_coef)\n","baby_coef %>%\n","  df_stats(~ slope, quantile(c(0.05, 0.5, 0.95)))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Categorical Predictor"],"metadata":{}},{"source":["smoker_reg <- lm(birth_weight ~ maternal_smoker, data = baby)\n","resample_baby <- function(...) {\n","  baby_resample <- baby %>%\n","    sample_n(nrow(baby), replace = TRUE)\n","\n","  baby_resample %>%\n","    lm(birth_weight ~ maternal_smoker, data = .) %>%\n","    coef(.) %>%\n","    .[2] %>%\n","    data.frame()\n","}\n","baby_coef <- map(1:10000, resample_baby) %>%\n","  bind_rows()\n","names(baby_coef) <- 'slope'"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["gf_density(~ slope, data = baby_coef)\n","baby_coef %>%\n","  df_stats(~ slope, quantile(c(0.05, 0.5, 0.95)))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## Combine the two predictors\n"," What happens if we would like to combine the two predictors? Shown above is that the number of gestational days has a moderate relationship to the baby weight, therefore exploring the effects of smoking, it would be nice to remove the effect of gestational days from the baby weight. More specifically, this essentially allows us to make comparisons on the effect of smoking for the **same** gestational days. One way to think about this is through conditional means. Exploration of these visually first can be particularly helpful."],"metadata":{}},{"source":["gf_point(birth_weight ~ gestational_days, data = baby, size = 3) %>%\n","  gf_smooth() %>%\n","  gf_facet_wrap(~ maternal_smoker)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["baby_reg_smoker <- lm(birth_weight ~ I(gestational_days - mean(gestational_days)) + maternal_smoker, data = baby)\n","coef(baby_reg_smoker)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" We can write out the regression equation similar to before:\n","\n"," \\begin{equation}\n","  birth\\_weight = 122.67 + 0.49 (gestational\\_days - mean(gestational\\_days) - 8.17 maternal\\_smoker + \\epsilon\n"," \\end{equation}\n","\n"," Let's explore how these are interpreted.\n","\n"," ### Distribution of Effects\n"," Similar to before, the distribution of effects can be obtained with the following steps:\n"," 1. Resample the observed data available, with replacement\n"," 2. Estimate linear model coefficients.\n"," 3. Save terms of interest\n"," 4. Repeat steps 1 - 3 many times\n"," 5. Explore the distribution of median differences from the many resampled data sets."],"metadata":{}},{"source":["resample_baby <- function(...) {\n","  baby_resample <- baby %>%\n","    sample_n(nrow(baby), replace = TRUE)\n","\n","  baby_resample %>%\n","    lm(birth_weight ~ I(gestational_days - mean(gestational_days)) + maternal_smoker, data = .) %>%\n","    tidy(.) %>%\n","    select(term, estimate)\n","}\n","resample_baby()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["coef_baby <- map(1:10000, resample_baby) %>%\n","  bind_rows()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["coef_baby %>%\n","  gf_density(~ estimate) %>% \n","  gf_facet_wrap(~ term, scales = 'free')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## Interactions\n"," One additional idea that can be quite powerful is the idea of interactions. This was indirectly shown earlier in the course with classification and regression trees, where the models after each split re-evaluated which attributes were most helpful. In this way, the same attribute could be used in different places with different scores identifying the split. A similar idea can be explored in the regression framework, where the idea is that there are differential effects for different groups. This can be shown visually:"],"metadata":{}},{"source":["gf_point(birth_weight ~ gestational_days, data = baby, size = 3) %>%\n","  gf_smooth() %>%\n","  gf_facet_wrap(~ maternal_smoker)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["baby_reg_int <- lm(birth_weight ~ I(gestational_days - mean(gestational_days)) * maternal_smoker, data = baby)\n","coef(baby_reg_int)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["resample_baby <- function(...) {\n","  baby_resample <- baby %>%\n","    sample_n(nrow(baby), replace = TRUE)\n","\n","  baby_resample %>%\n","    lm(birth_weight ~ I(gestational_days - mean(gestational_days)) * maternal_smoker, data = .) %>%\n","    tidy(.) %>%\n","    select(term, estimate)\n","}\n","resample_baby()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["coef_baby <- map(1:10000, resample_baby) %>%\n","  bind_rows()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["coef_baby %>%\n","  gf_density(~ estimate) %>% \n","  gf_facet_wrap(~ term, scales = 'free')\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Evaluating model fit\n"," As discussed earlier, R-square is a measure of overall model fit. These can be compared across the different models to see which one may be doing the best and explaining the most variation in the baby's birth weight."],"metadata":{}},{"source":["summary(baby_reg)$r.square\n","summary(smoker_reg)$r.square\n","summary(baby_reg_smoker)$r.square\n","summary(baby_reg_int)$r.square"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","kernelspec":{
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },"language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  },"mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}