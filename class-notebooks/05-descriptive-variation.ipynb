{"cells":[{"cell_type":"markdown","source":["    ## Applying Functions to Data - Part 2"],"metadata":{}},{"cell_type":"markdown","source":["    ## Setup\n","\n","    We are going to use some real data about higher education institutions from the college scorecard (https://collegescorecard.ed.gov/) to explore the types of conclusions we can make from the data. The college scorecard releases data on higher education institutions to help make the institutions more transparent and provide a place for parents, students, educators, etc can get information about specific instituations from a third party (i.e. US Department of Education).\n","\n","    ### Loading R packages"],"metadata":{}},{"source":[".libPaths('../RPackages')\n","\n","library(tidyverse)\n","library(ggformula)\n","library(mosaic)\n","\n","theme_set(theme_bw())\n","\n","college_score <- read_csv(\"https://raw.githubusercontent.com/lebebr01/statthink/master/data-raw/College-scorecard-4143.csv\", guess_max = 10000)\n","head(college_score)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["    ## Measures of Variation\n","\n","    So far we have focused primarily on applying functions to columns of data to provide a single numeric summary for where the center of the distribution may lie. The center of the distribution is important, however the primary goal in research and with statistics is to try to understand the variation in the distribution.\n","\n","    One crude measure of variation that is intuitive is the range of a variable. The range is the difference between the smallest and the largest number in the data. We can compute this with the `df_stats()` function."],"metadata":{}},{"source":["college_score %>%\n","  df_stats(~ adm_rate, range)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["    The details of the `df_stats()` function are in the previous course notes. The output for this computation returns two values, the minimum and maximum value in the data and unsurprisingly, is 0 and 1 respectively. The range is most useful as a data checking process to ensure that the variable contains values that are theoretically possible, which is true in this case. The range is known as a biased statistic in that it will almost always be smaller than the population value. Therefore, we would like a better statistic for measures of variation.\n","\n","   ### Robust measure of variation\n","   A robust measure of variation that often is used in tandem with the median is the interquartile range (IQR). This statistic can be calculated in two ways, either using the `IQR()` or `quantile()` function. Both are presented below."],"metadata":{}},{"source":["college_score %>%\n","  df_stats(~ adm_rate, IQR, quantile(c(0.25, 0.75)), nice_names = TRUE)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["   The IQR is the difference between the 75th and 25th percentiles and in this example equals 0.285 or about 28.5%. As the IQR represents differences in percentiles, we could say that the middle 50% of the distribution is found between 55% and 84% and the middle 50% is spread out by about 28.5%. The idea behind the IQR representing differences in percentiles allows us to extend this to different percentiles that may be more directly interpretable for a given situation. For example, suppose we wanted to know how spread out the middle 80% of the distribution is. We can do this directly by computing the 90th and 10th percentiles and finding the difference between the two."],"metadata":{}},{"source":["mid_80 <- college_score %>%\n","  df_stats(~ adm_rate, quantile(c(0.1, 0.9)), nice_names = TRUE)\n","mid_80\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["   As you can see, once you extend the amount of the distribution contained, the distance increases, now to 0.555 or 55.5% the the range of the middle 80% of the admission rate distribution. We can also visualize what this looks like."],"metadata":{}},{"source":["gf_histogram(~ adm_rate, data = college_score, bins = 30, color = 'black') %>%\n","  gf_vline(color = 'blue', xintercept = ~ value, data = gather(mid_80), size = 1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["   We can also view the exact percentages using the empirical cumulative density function."],"metadata":{}},{"source":["gf_ecdf(~ adm_rate, data = college_score) %>%\n","  gf_vline(color = 'blue', xintercept = ~ value, data = gather(mid_80), size = 1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["  ### Variation by Group\n","  These statistics can also be calculated by different grouping variables similar to what was done with statisitcs of center. Now the variable of interest is on the left-hand side of the equation and the grouping variable is on the right hand side."],"metadata":{}},{"source":["iqr_groups <- college_score %>%\n","  df_stats(adm_rate ~ region, IQR, quantile(c(0.25, 0.75)), nice_names = TRUE)\n","iqr_groups\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["  This can also be visualized to see how these statistics vary across the groups."],"metadata":{}},{"source":["gf_histogram(~ adm_rate, data = college_score, bins = 30, color = 'black') %>%\n","  gf_vline(color = 'blue', xintercept = ~ value, \n","     data = filter(pivot_longer(iqr_groups, IQR_adm_rate:'X75.'), name %in% c('X25.', 'X75.')), size = 1) %>%\n","  gf_facet_wrap(~ region)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["  ## Other measures of variation\n","   There are many other variation measures that are used in statistics. We will apply a functional approach to these and try to visualize what they are trying to represent. The statistics discussed here represent deviations from the mean, either the average absolute deviation or the average squared deviation."],"metadata":{}},{"source":["college_score %>%\n","  df_stats(~ adm_rate, sd, var)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" In order to compute the mean absolute error, we first need to define a new function."],"metadata":{}},{"source":["mae <- function(x, na.rm = TRUE, ...) {\n","  avg <- mean(x, na.rm = na.rm, ...)\n","  abs_avg <- abs(x - avg)\n","  \n","  mean(abs_avg)\n","} \n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" We can now use this new function just like any other function."],"metadata":{}},{"source":["college_score %>%\n","  df_stats(~ adm_rate, sd, var, mae)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 }}