{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Linear Regression - Categorical Predictor Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Description of the Data\n",
    "  These data contain information on mother's and baby's health for 1,174 pregnant women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggformula)\n",
    "library(mosaic)\n",
    "\n",
    "theme_set(theme_bw(base_size = 18))\n",
    "\n",
    "baby <- read_csv(\"https://raw.githubusercontent.com/lebebr01/statthink/master/data-raw/baby.csv\")\n",
    "baby <- baby %>%\n",
    "  mutate(smoker = ifelse(maternal_smoker, 1, 0))\n",
    "head(baby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ## Linear Regression - Categorical Predictor Refresher\n",
    "  Now it is time to fit a model to the data here to explore if there indeed is a difference in the population. We know descriptively there is a difference in the two group means and medians, but is this difference large enough to be practical? The model is fitted similar to before with the `lm()` function and a similar formula as before. The outcome (birth weight) is to the left of the `~` and the predictor (maternal smoking status) is to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "smoker_reg <- lm(birth_weight ~ maternal_smoker, data = baby)\n",
    "coef(smoker_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Inference\n",
    "  Similar to the continuous predictor, resampling/bootstrap takes a similar method in the case with a single categorical predictor.\n",
    "\n",
    "  In order to get some sense of the amount of error in the estimate of the linear slope here, a bootstrap can be done to provide some evidence of the likely range of slope values. The bootstrap will take the following general steps:\n",
    "  1. Resample the observed data available, with replacement\n",
    "  2. Fit the same linear regression model as above.\n",
    "  3. Save the slope coefficient representing the relationship between birth weight and gestational days\n",
    "  4. Repeat steps 1 - 3 many times\n",
    "  5. Explore the distribution of slope estimates from the many resampled data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "resample_baby <- function(...) {\n",
    "  baby_resample <- baby %>%\n",
    "    sample_n(nrow(baby), replace = TRUE)\n",
    "\n",
    "  baby_resample %>%\n",
    "    lm(birth_weight ~ maternal_smoker, data = .) %>%\n",
    "    coef(.) %>%\n",
    "    .[2] %>%\n",
    "    data.frame()\n",
    "}\n",
    "\n",
    "resample_baby()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Now that there is a function that does steps 1 - 3, these processes can now be repeated many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "baby_coef <- map(1:10000, resample_baby) %>%\n",
    "  bind_rows()\n",
    "names(baby_coef) <- 'slope'\n",
    "\n",
    "gf_density(~ slope, data = baby_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "baby_coef %>%\n",
    "  df_stats(~ slope, quantile(c(0.05, 0.5, 0.95)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## More than 2 categorical groups\n",
    " Before the model contained one attribute that represented two groups. What happens when there are more than two groups for an attribute? To explore this, the college scorecard data will be used again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "college_score <- read_csv(\"https://raw.githubusercontent.com/lebebr01/statthink/master/data-raw/College-scorecard-4143.csv\", guess_max = 10000)\n",
    "head(college_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Explore distribution 3 groups\n",
    " Early in the course, the distribution of admission rates by the primary degree that the institution grants was explored. Below is a violin plot that shows these three distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gf_violin(adm_rate ~ preddeg, data = college_score, fill = 'gray85', \n",
    "          size = 1, draw_quantiles = c(0.1, 0.5, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There may be some small differences between these groups, but more formally we can test this to understand the amount of uncertainty in the average of the distributions. This again will make use of the `lm()` function in R and the formula is very similar to what was done before and mimics the formula from the violin plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "adm_model <- lm(adm_rate ~ preddeg, data = college_score)\n",
    "coef(adm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Guesses as to what these coefficients represent? How were the categorical groups turned into the different elements in the model?\n",
    "\n",
    " ## Overall model fit\n",
    " There is a measure of overall model fit that is commonly used in the research literature for linear regression models, called R-squared. R-squared represents the proportion of variation in the outcome that is explained by the attributes in the model. The statistic ranges from 0 to 1 where values closer to 1 indicate larger percentages of variation explained. This can be extracted from the model directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(adm_model)$r.squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Another one can be computed from the baby data where the birth weight was the outcome and gestational days was the primary attribute used as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "baby_reg <- lm(birth_weight ~ gestational_days, data = baby)\n",
    "summary(baby_reg)$r.squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For models with a single predictor variable, R-squared is the correlation coefficient squared. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "cor(birth_weight ~ gestational_days, data = baby) ^ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residual Standard Error\n",
    "\n",
    "Another metric to evaluate model fit is a statistic called the residual standard error. This statistic is interpreted just like the standard deviation, but instead of being the average distance data are from the mean, the residual standard error is the average distance data points are from the regression line. \n",
    "\n",
    "Similar to the standard deviation, in general, smaller values of the residual standard error are better. However, the scale of this statistic is dependent on the scale of the outcome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(baby_reg)$sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gf_point(birth_weight ~ gestational_days, data = baby) %>%\n",
    "   gf_smooth(method = 'lm', size = 1) %>%\n",
    "   gf_labs(y = \"Birth Weight\", \n",
    "                  x = \"Gestational Days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(adm_model)$sigma"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
